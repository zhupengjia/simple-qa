{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"/home/pzhu/data/qa/squad2_model/checkpoint-193450\"\n",
    "predict_file = \"data/dev-v2.0.json\"\n",
    "model_name = \"xlnet-large-cased\"\n",
    "output_prediction_file = \"data/predictions.json\"\n",
    "output_nbest_file = \"data/nbest_predictions.json\"\n",
    "output_null_log_odds_file = \"data/null_odds.json\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import XLNetForQuestionAnswering\n",
    "model = XLNetForQuestionAnswering.from_pretrained(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlnet_qa.squad2_reader import SQuAD2Reader\n",
    "\n",
    "reader = SQuAD2Reader(is_training=False)\n",
    "dataset, examples, features = reader.squad_data(predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1543/1543 [14:02<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import SequentialSampler, DataLoader\n",
    "from xlnet_qa.utils_squad import RawResultExtended, write_predictions_extended\n",
    "\n",
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=8)\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "all_results = []\n",
    "for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids = batch[0],\n",
    "                        attention_mask = batch[1],\n",
    "                        token_type_ids = batch[2],\n",
    "                        cls_index = batch[4],\n",
    "                        p_mask = batch[5]\n",
    "                       )\n",
    "    for i, example_index in enumerate(batch[3]):\n",
    "        eval_feature = features[example_index.item()]\n",
    "        unique_id = int(eval_feature.unique_id)\n",
    "        result = RawResultExtended(unique_id= unique_id,\n",
    "                                   start_top_log_probs  = to_list(outputs[0][i]),\n",
    "                                   start_top_index      = to_list(outputs[1][i]),\n",
    "                                   end_top_log_probs    = to_list(outputs[2][i]),\n",
    "                                   end_top_index        = to_list(outputs[3][i]),\n",
    "                                   cls_logits           = to_list(outputs[4][i])\n",
    "                                  )\n",
    "        \n",
    "        all_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_exact': 50.07159100480081,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 50.07580224037733,\n",
       " 'best_f1_thresh': -0.8465023040771484,\n",
       " 'has_ans_exact': 0.0020242914979757085,\n",
       " 'has_ans_f1': 0.059967068372362826}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_predictions_extended([examples], [features], all_results, 20, 30,\n",
    "                  output_prediction_file, output_nbest_file, output_null_log_odds_file,\n",
    "                  predict_file, model.config.start_n_top, model.config.end_n_top,\n",
    "                  True, reader.tokenizer, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 6.3505432493893705,\n",
      "  \"f1\": 9.243533911491307,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 0.20242914979757085,\n",
      "  \"HasAns_f1\": 5.996706837236289,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 12.48107653490328,\n",
      "  \"NoAns_f1\": 12.48107653490328,\n",
      "  \"NoAns_total\": 5945,\n",
      "  \"best_exact\": 50.07159100480081,\n",
      "  \"best_exact_thresh\": 0.0,\n",
      "  \"best_f1\": 50.07580224037733,\n",
      "  \"best_f1_thresh\": -0.8465023040771484\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from xlnet_qa.utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad\n",
    "evaluate_options = EVAL_OPTS(data_file=predict_file,\n",
    "                                 pred_file=output_prediction_file,\n",
    "                                 na_prob_file=output_null_log_odds_file)\n",
    "results = evaluate_on_squad(evaluate_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
